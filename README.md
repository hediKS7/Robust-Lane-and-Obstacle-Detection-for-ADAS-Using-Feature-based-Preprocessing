Here's a comprehensive, ready-to-paste `README.md` file with detailed explanations and system architecture:

---

# ğŸš— Robust Lane and Obstacle Detection for ADAS Using Feature-based Preprocessing

<div align="center">

![ADAS System](https://img.shields.io/badge/ADAS-Computer%20Vision-blue)
![Python](https://img.shields.io/badge/Python-3.8%2B-green)
![OpenCV](https://img.shields.io/badge/OpenCV-4.5%2B-orange)
![License](https://img.shields.io/badge/License-Academic-lightgrey)

**Advanced Driver Assistance System for robust lane and obstacle detection under challenging conditions**

</div>

---

## ğŸ“‹ Table of Contents
- [Project Overview](#-project-overview)
- [Key Features](#-key-features)
- [System Architecture](#-system-architecture)
- [Methodology Details](#-methodology-details)
- [Installation](#-installation)
- [Usage](#-usage)
- [Evaluation Results](#-evaluation-results)
- [Project Structure](#-project-structure)
- [Team](#-team)
- [License](#-license)

---

## ğŸ¯ Project Overview

This project implements a **robust computer vision system** for Advanced Driver Assistance Systems (ADAS) that reliably detects lane markings and road obstacles under various challenging conditions. Traditional ADAS systems often struggle with degraded visual inputs caused by weather, lighting variations, and poor road markings. Our approach combines **classical computer vision techniques** with **deep learning models** to create a hybrid system that maintains high detection accuracy even in suboptimal conditions.

### ğŸ” Problem Statement
- **Image degradation** in real driving conditions (rain, fog, shadows, motion blur)
- **Weak edge and feature visibility** of lane markings
- **High sensitivity** of detection algorithms to noisy inputs
- **Variable lighting conditions** affecting detection consistency

### ğŸ’¡ Proposed Solution
- **Feature-based preprocessing** using classical filters (Sobel, Prewitt, Laplacian, Gaussian)
- **Hybrid detection pipelines** combining traditional CV and CNN approaches
- **Multi-condition robustness** through adaptive preprocessing strategies
- **Real-time processing** capabilities for vehicle integration

---

## âœ¨ Key Features

| Feature | Description | Benefit |
|---------|-------------|---------|
| **Multi-Condition Robustness** | Works under low light, rain, fog, shadows, and motion blur | Reliable performance in real-world scenarios |
| **Dual Detection Pipelines** | Separate optimized pipelines for lanes and obstacles | Specialized processing for different detection tasks |
| **Classical Filter Preprocessing** | Sobel, Canny, Gaussian, and morphological operations | Enhanced edge visibility and noise reduction |
| **Hybrid Approach** | Combines filter-based methods with CNN architectures | Balances speed and accuracy |
| **Real-time Processing** | Optimized for vehicle-mounted hardware | Suitable for ADAS applications |
| **Interactive UI Demo** | Graphical interface for testing and visualization | Easy system evaluation and demonstration |

---

## ğŸ—ï¸ System Architecture

### High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VEHICLE-MOUNTED CAMERA                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMAGE ACQUISITION MODULE                  â”‚
â”‚  â€¢ Frame capture (1280Ã—720 @ 30fps)                         â”‚
â”‚  â€¢ Initial normalization and resizing                        â”‚
â”‚  â€¢ Buffering for continuous processing                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PREPROCESSING PIPELINE (CLASSICAL)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Gaussianâ”‚  â”‚  Sobel  â”‚  â”‚  Canny  â”‚  â”‚  ROI    â”‚        â”‚
â”‚  â”‚  Blur   â”‚â†’â”‚  Filter  â”‚â†’â”‚  Edge   â”‚â†’â”‚ Selectionâ”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚                 â”‚
                         â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LANE DETECTION â”‚    â”‚       OBSTACLE DETECTION            â”‚
â”‚    PIPELINE     â”‚    â”‚                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Hough Transformâ”‚   â”‚ â€¢ YOLO-based Detection             â”‚
â”‚ â€¢ Sliding Window â”‚   â”‚ â€¢ Instance Segmentation            â”‚
â”‚ â€¢ Polynomial Fit â”‚   â”‚ â€¢ Multi-class Classification       â”‚
â”‚ â€¢ Curved/Straightâ”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
                         â”‚             â”‚
                         â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FUSION & DECISION LAYER                   â”‚
â”‚  â€¢ Lane position validation                                 â”‚
â”‚  â€¢ Obstacle distance estimation                             â”‚
â”‚  â€¢ Risk assessment and alert generation                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUT VISUALIZATION                      â”‚
â”‚  â€¢ Overlay lanes on original video                          â”‚
â”‚  â€¢ Bounding boxes for obstacles                             â”‚
â”‚  â€¢ Warning indicators and alerts                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Pipeline Components

#### 1. **Image Acquisition Module**
- **Input**: Continuous stream from front-facing vehicle camera
- **Resolution**: 1280Ã—720 pixels
- **Frame Rate**: 30 FPS (adjustable)
- **Pre-processing**: Automatic white balance, exposure adjustment

#### 2. **Preprocessing Module**
```
Raw Image â†’ Grayscale Conversion â†’ Noise Reduction â†’ Edge Enhancement â†’ ROI Extraction
    â”‚              â”‚                   â”‚                  â”‚                  â”‚
    â”‚              â”‚              Gaussian Blur      Sobel/Canny        Polygon Mask
    â”‚              â”‚              (Ïƒ=1.5)         (Thresholds: 50,150)  (Trapezoidal)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3. **Lane Detection Pipeline**
```
Two Parallel Approaches:
A. Classical Approach (Straight Lanes):
   Preprocessed Image â†’ Canny Edge â†’ Hough Transform â†’ Line Clustering â†’ Lane Marking
  
B. Advanced Approach (Curved Lanes):
   Preprocessed Image â†’ Sliding Window Search â†’ Polynomial Fitting â†’ Lane Tracking
   
   Sliding Window Process:
   1. Histogram peak detection for lane base
   2. 9 vertical windows (height: 80px)
   3. Window recentering based on detected pixels
   4. 2nd-order polynomial fitting: x = AyÂ² + By + C
```

#### 4. **Obstacle Detection Pipeline**
```
Input Frame â†’ YOLO Network â†’ Bounding Boxes â†’ Non-Max Suppression â†’ Classification
                    â”‚
                    â”œâ”€â”€â†’ Segmentation Mask (optional)
                    â”‚
                    â””â”€â”€â†’ Distance Estimation (using camera calibration)
```

#### 5. **CNN-Based Lane Detection (Alternative)**
```
Architecture: Encoder-Decoder with Skip Connections
Input: 640Ã—360 RGB â†’ Encoder (ResNet-18) â†’ Decoder (Transpose Conv) â†’ Output: Binary Mask

Training Details:
- Dataset: TuSimple (3,626 clips, 20 frames/clip)
- Loss: Binary Cross-Entropy + Dice Loss
- Optimizer: Adam (lr=1e-4)
- Batch Size: 8
```

---

## ğŸ“Š Methodology Details

### Preprocessing Techniques

#### **Classical Filters Implementation**
```python
# Example preprocessing pipeline
def preprocess_frame(image):
    # 1. Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # 2. Gaussian blur for noise reduction
    blurred = cv2.GaussianBlur(gray, (5, 5), 1.5)
    
    # 3. Sobel edge detection
    sobel_x = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)
    sobel_y = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)
    magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
    
    # 4. Canny edge detection
    edges = cv2.Canny(blurred, 50, 150)
    
    # 5. Region of Interest masking
    roi = apply_roi_mask(edges)
    
    return roi
```

#### **Hough Transform for Line Detection**
- **Coordinate System**: Ï = xÂ·cosÎ¸ + yÂ·sinÎ¸
- **Parameter Space**: Î¸ âˆˆ [0, Ï€], Ï âˆˆ [-D, D] where D = âˆš(widthÂ² + heightÂ²)
- **Voting Threshold**: Minimum 50 intersections for line acceptance
- **Line Grouping**: Angular similarity within Â±10 degrees

#### **Sliding Window Algorithm**
```python
def sliding_window_search(binary_image):
    # Take histogram of bottom half
    histogram = np.sum(binary_image[binary_image.shape[0]//2:,:], axis=0)
    
    # Find left and right peaks
    midpoint = histogram.shape[0] // 2
    left_base = np.argmax(histogram[:midpoint])
    right_base = np.argmax(histogram[midpoint:]) + midpoint
    
    # Set window parameters
    n_windows = 9
    window_height = binary_image.shape[0] // n_windows
    margin = 100
    
    # Iterate through windows
    for window in range(n_windows):
        # Window boundaries
        win_y_low = binary_image.shape[0] - (window + 1) * window_height
        win_y_high = binary_image.shape[0] - window * window_height
        
        # Recenter window if enough pixels found
        # ... implementation continues
```

---

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- 4GB+ RAM (8GB recommended)
- GPU with CUDA support (optional, for CNN pipeline)

### Step-by-Step Setup

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/robust-lane-obstacle-detection.git
cd robust-lane-obstacle-detection

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Download pretrained models (optional)
python scripts/download_models.py

# 5. Run verification test
python test_installation.py
```

### Required Packages (`requirements.txt`)
```
# Core Computer Vision
opencv-python==4.5.5.64
opencv-contrib-python==4.5.5.64
numpy==1.21.0
scikit-image==0.19.0
Pillow==9.0.0

# Machine Learning
torch==1.10.0
torchvision==0.11.0
scikit-learn==1.0.0
tensorflow==2.7.0  # Optional for CNN pipeline

# Utilities
matplotlib==3.5.0
seaborn==0.11.2
pandas==1.3.5
tqdm==4.62.3

# GUI (for demo)
PyQt5==5.15.6
pygame==2.1.0
```

---

## ğŸ’» Usage

### Basic Lane Detection
```python
from lane_detection import LaneDetector

# Initialize detector
detector = LaneDetector(mode='hybrid')  # Options: 'classical', 'cnn', 'hybrid'

# Process single image
image = cv2.imread('test_image.jpg')
lanes, annotated = detector.detect(image)

# Process video
detector.process_video('input_video.mp4', 'output_video.mp4')
```

### Obstacle Detection
```python
from obstacle_detection import ObstacleDetector

detector = ObstacleDetector(model_type='yolov5')  # Options: 'yolov5', 'faster_rcnn'

# Detect obstacles
obstacles = detector.detect(image)

# Visualize results
annotated = detector.visualize(image, obstacles)
```

### Run Interactive Demo
```bash
# Launch the GUI application
python ui_demo/main.py

# Or run command-line demo
python demo.py --input video.mp4 --mode both --show-ui
```

### Command Line Interface
```bash
# Lane detection only
python main.py --mode lane --input data/test_video.mp4 --output results/

# Obstacle detection only
python main.py --mode obstacle --model yolov5s --conf 0.5

# Full pipeline (lanes + obstacles)
python main.py --mode full --input 0  # 0 for webcam

# Evaluation on dataset
python evaluate.py --dataset tusimple --metrics all
```

---

## ğŸ“ˆ Evaluation Results

### Performance Metrics

#### **Lane Detection Accuracy**
| Condition | Classical Method | CNN Method | Hybrid Method |
|-----------|-----------------|------------|---------------|
| Daylight | 96.2% | 97.8% | 98.1% |
| Night | 78.5% | 89.2% | 92.4% |
| Rain | 72.3% | 85.6% | 88.9% |
| Fog | 65.8% | 82.1% | 86.3% |
| **Average** | **78.2%** | **88.7%** | **91.4%** |

#### **Obstacle Detection (mAP@50)**
| Class | Precision | Recall | F1-Score | mAP@50 |
|-------|-----------|--------|----------|--------|
| All Objects | 0.8347 | 0.7903 | 0.8113 | 0.8182 |
| Speed Bumps | 0.9557 | 1.0000 | 0.9774 | 0.9950 |
| Potholes | 0.7136 | 0.5806 | 0.6403 | 0.6414 |

#### **Processing Speed**
| Pipeline | FPS (CPU) | FPS (GPU) | Memory Usage |
|----------|-----------|-----------|--------------|
| Classical Only | 45-50 | N/A | ~500MB |
| CNN Only | 8-10 | 25-30 | ~2GB |
| Hybrid | 15-20 | 35-40 | ~1.5GB |

### Robustness Across Conditions
![Robustness Comparison](docs/images/robustness_chart.png)
*The hybrid approach maintains >85% accuracy across all tested conditions*

---

## ğŸ“ Project Structure

```
robust-lane-obstacle-detection/
â”‚
â”œâ”€â”€ data/                           # Dataset storage
â”‚   â”œâ”€â”€ tusimple/                   # TuSimple dataset
â”‚   â”œâ”€â”€ custom/                     # Custom collected data
â”‚   â””â”€â”€ samples/                    # Sample images/videos
â”‚
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ preprocessing/              # Image preprocessing
â”‚   â”‚   â”œâ”€â”€ filters.py             # Classical filters
â”‚   â”‚   â”œâ”€â”€ enhancement.py         # Contrast enhancement
â”‚   â”‚   â””â”€â”€ roi.py                 # Region of interest
â”‚   â”‚
â”‚   â”œâ”€â”€ lane_detection/            # Lane detection algorithms
â”‚   â”‚   â”œâ”€â”€ classical/             # Traditional methods
â”‚   â”‚   â”‚   â”œâ”€â”€ hough_transform.py
â”‚   â”‚   â”‚   â”œâ”€â”€ sliding_window.py
â”‚   â”‚   â”‚   â””â”€â”€ polynomial_fit.py
â”‚   â”‚   â”œâ”€â”€ cnn/                   # Deep learning approach
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”‚   â””â”€â”€ inference.py
â”‚   â”‚   â””â”€â”€ hybrid.py              # Combined approach
â”‚   â”‚
â”‚   â”œâ”€â”€ obstacle_detection/        # Obstacle detection
â”‚   â”‚   â”œâ”€â”€ yolo/                  # YOLO implementation
â”‚   â”‚   â”œâ”€â”€ segmentation/          # Instance segmentation
â”‚   â”‚   â””â”€â”€ distance_estimation.py # Depth estimation
â”‚   â”‚
â”‚   â”œâ”€â”€ fusion/                    # Data fusion module
â”‚   â”‚   â”œâ”€â”€ lane_obstacle_fusion.py
â”‚   â”‚   â””â”€â”€ decision_making.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ui_demo/                   # Graphical interface
â”‚   â”‚   â”œâ”€â”€ main_window.py
â”‚   â”‚   â”œâ”€â”€ video_player.py
â”‚   â”‚   â””â”€â”€ controls.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utility functions
â”‚       â”œâ”€â”€ calibration.py
â”‚       â”œâ”€â”€ visualization.py
â”‚       â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ models/                         # Pretrained models
â”‚   â”œâ”€â”€ lane_cnn.pth
â”‚   â”œâ”€â”€ yolov5s.pt
â”‚   â””â”€â”€ hybrid_model.pt
â”‚
â”œâ”€â”€ experiments/                    # Experiment logs
â”‚   â”œâ”€â”€ classical_experiments/
â”‚   â”œâ”€â”€ cnn_experiments/
â”‚   â””â”€â”€ hybrid_experiments/
â”‚
â”œâ”€â”€ results/                        # Output results
â”‚   â”œâ”€â”€ detection_outputs/
â”‚   â”œâ”€â”€ evaluation_metrics/
â”‚   â””â”€â”€ visualization/
â”‚
â”œâ”€â”€ tests/                          # Unit tests
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_lane_detection.py
â”‚   â””â”€â”€ test_obstacle_detection.py
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ presentation.pdf
â”‚   â”œâ”€â”€ architecture_diagrams/
â”‚   â””â”€â”€ api_documentation.md
â”‚
â”œâ”€â”€ configs/                        # Configuration files
â”‚   â”œâ”€â”€ lane_config.yaml
â”‚   â”œâ”€â”€ obstacle_config.yaml
â”‚   â””â”€â”€ system_config.yaml
â”‚
â”œâ”€â”€ scripts/                        # Helper scripts
â”‚   â”œâ”€â”€ download_datasets.py
â”‚   â”œâ”€â”€ train_all_models.py
â”‚   â””â”€â”€ benchmark.py
â”‚
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ setup.py                       # Package installation
â”œâ”€â”€ LICENSE                        # License file
â””â”€â”€ README.md                      # This file
```

---

## ğŸ‘¥ Team

| Role | Name | Contribution |
|------|------|--------------|
| **Team Member** | Oumaima Werghemmi | Lane detection algorithms, CNN pipeline, System integration |
| **Team Member** | Hedi Ksentini | Obstacle detection, Classical preprocessing, UI development |
| **Academic Supervisor** | Mrs. Dorra Sallemi | Project guidance, Methodology review, Evaluation |

**Institution**: Ã‰cole Polytechnique de Tunisie, UniversitÃ© de Carthage  
**Department**: Computer Science & Engineering  
**Academic Year**: 2023-2024

---

## ğŸ“„ License

This project is developed for academic purposes as part of the final year project at Ã‰cole Polytechnique de Tunisie. The code is available for educational and research purposes. For commercial use, please contact the authors.

```
Copyright (c) 2024 Oumaima Werghemmi & Hedi Ksentini

Permission is hereby granted for academic and research use only, subject to the following conditions:
1. The above copyright notice and this permission notice shall be included in all copies.
2. Appropriate credit must be given to the original authors.
3. Commercial use requires explicit written permission from the authors.
```

---

## ğŸ™ Acknowledgments

We would like to express our gratitude to:

- **Mrs. Dorra Sallemi** for her continuous guidance and support
- **Ã‰cole Polytechnique de Tunisie** for providing the academic framework
- **TuSimple** for making their lane detection dataset publicly available
- The **OpenCV community** for their excellent computer vision library
- All **open-source contributors** whose work made this project possible

---

## ğŸ”— References

1. TuSimple Lane Detection Challenge Dataset (2017)
2. Redmon, J., & Farhadi, A. (2018). YOLOv3: An Incremental Improvement
3. Canny, J. (1986). A Computational Approach to Edge Detection
4. Hough, P. V. C. (1962). Method and means for recognizing complex patterns

---

<div align="center">

### ğŸš€ Ready to enhance your ADAS capabilities?

**Star this repo if you find it useful!**

[Report Bug](https://github.com/yourusername/robust-lane-obstacle-detection/issues) Â· 
[Request Feature](https://github.com/yourusername/robust-lane-obstacle-detection/issues) Â· 
[Contact Authors](mailto:contact@example.com)

</div>
